{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Proyecto productividad trabajo remoto\"\n",
        "author: \"Leandro Soto Miranda\"\n",
        "date: \"2024-10-24\"\n",
        "format: \n",
        "  html: \n",
        "    toc: true \n",
        "    code-fold: true\n",
        "---\n",
        "\n",
        "\n",
        "## 1. Definir problema\n",
        "\n",
        "- En este proyecto, analizaremos un conjunto de datos de rendimiento de estudiantes con el objetivo de predecir el puntaje del examen de los estudiantes para generar un impacto en el rendimiento de los alumnos en el caso de que su rendimiento en los exámenes sea mejor compartiendo insights para la mejora del rendimiento del estudiante y se reduzca la posibilidad de desaprobar el examen.\n",
        "\n",
        "## 2. Recopilación de datos\n"
      ],
      "id": "48d92ffa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importación de librerías\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "# Carga de datos\n",
        "df = pd.read_csv('data.csv', sep=\",\")\n",
        "\n",
        "# Resumen estadístico\n",
        "# Mostrar las primeras filas del dataset\n",
        "print(\"Primeras filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Mostrar información general del dataset\n",
        "print(\"\\nInformación del dataset:\")\n",
        "print(df.info())\n",
        "\n",
        "# Descripción estadística básica del dataset\n",
        "print(\"\\nDescripción estadística:\")\n",
        "print(df.describe())\n",
        "\n",
        "info = df.shape\n",
        "print(\"\\nLa cantidad de filas y columnas en nuestro dataframe es de:\",info)\n",
        "\n",
        "tipos = df.dtypes\n",
        "print(\"\\nTipos de datos presentes en el dataset:\\n\",tipos)"
      ],
      "id": "de4a39a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análisis de datos por Variable\n",
        "## Análisis de datos cuantitativos\n"
      ],
      "id": "6b33d291"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función para el análisis univariado de variables cuantitativas\n",
        "def analizar_variable_cuantitativa(df, columna):\n",
        "    mean = np.mean(df[columna])\n",
        "    median = np.median(df[columna])\n",
        "    std = np.std(df[columna])\n",
        "    min_value = np.min(df[columna])\n",
        "    max_value = np.max(df[columna])\n",
        "\n",
        "    print(f\"Análisis de la Variable '{columna}'\")\n",
        "    print(f\"Media: {mean:.2f}\")\n",
        "    print(f\"Mediana: {median:.2f}\")\n",
        "    print(f\"Desviación Estándar: {std:.2f}\")\n",
        "    print(f\"Valor Mínimo: {min_value:.2f}\")\n",
        "    print(f\"Valor Máximo: {max_value:.2f}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Visualización de la distribución (Histograma con KDE)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[columna], bins=30, kde=True, color='#4C72B0')\n",
        "    plt.title(f'Distribución de {columna}')\n",
        "    plt.xlabel(columna)\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.show()\n",
        "\n",
        "# Aplicar la función a todas las columnas numéricas del dataframe\n",
        "columnas_cuantitativas = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "for columna in columnas_cuantitativas:\n",
        "    analizar_variable_cuantitativa(df, columna)"
      ],
      "id": "403e1cdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análisis de datos cualitativos\n"
      ],
      "id": "7d011063"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función para el análisis univariado de variables categóricas\n",
        "def analizar_variable_categorica(df, columna):\n",
        "    values_counts = df[columna].value_counts()\n",
        "    moda = values_counts.idxmax()\n",
        "\n",
        "    print(f\"Análisis Univariado de la Variable '{columna}'\")\n",
        "    print(f\"Frecuencia de las categorías:\\n{values_counts}\")\n",
        "    print(f\"Moda (Categoría más frecuente): {moda}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Visualización de la distribución\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(\n",
        "        x=columna, \n",
        "        data=df[df[columna].isin(values_counts.index)], \n",
        "        order=values_counts.index, \n",
        "        palette='Set2'\n",
        "    )\n",
        "    plt.title(f'Distribución de {columna}')\n",
        "    plt.xlabel(columna)\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Aplicar la función a todas las columnas categóricas del dataframe\n",
        "columnas_categoricas = df.select_dtypes(include=['object']).columns\n",
        "for columna in columnas_categoricas:\n",
        "    analizar_variable_categorica(df, columna)"
      ],
      "id": "1ae539e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verificar si hay patrones o relaciones presentes entre variables"
      ],
      "id": "ae4298e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.scatterplot(x='Productivity_Score', y='Employment_Type', data=df)\n",
        "plt.title('Relación entre Horas de Estudio y Puntuación de Examen')\n",
        "plt.xlabel('Employment_Type')\n",
        "plt.ylabel('Puntuación de Examen')\n",
        "plt.show()"
      ],
      "id": "752591ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.scatterplot(x='Attendance', y='Exam_Score', data=df)\n",
        "plt.title('Relación entre Horas de Estudio y Puntuación de Examen')\n",
        "plt.xlabel('Horas de Estudio')\n",
        "plt.ylabel('Puntuación de Examen')\n",
        "plt.show()"
      ],
      "id": "98f5bfec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verificar si hay valores nulos en el dataset\n",
        "### Corrección de valores nulos presentes en el dataset"
      ],
      "id": "6db6f97a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())"
      ],
      "id": "3a644bce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lista de las columnas categóricas que deseas reemplazar por la moda\n",
        "categorical_columns = ['Parental_Education_Level', 'Distance_from_Home', 'Teacher_Quality']\n",
        "\n",
        "# Iterar sobre cada columna y reemplazar los valores nulos con la moda\n",
        "for column in categorical_columns:\n",
        "    mode_value = df[column].mode()[0]  # Obtener la moda (el valor más frecuente)\n",
        "    df[column].fillna(mode_value, inplace=True)\n",
        "    print(f\"Valores nulos en '{column}' reemplazados por la moda: '{mode_value}'\")"
      ],
      "id": "ed180d33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Verificar si hay valores atípicos"
      ],
      "id": "f02c86bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def generar_boxplot(df, columna):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=df, x=columna, palette='Set2')\n",
        "    plt.title(f'Boxplot de {columna}')\n",
        "    plt.xlabel(columna)\n",
        "    plt.show()\n",
        "\n",
        "# Aplicar la función a todas las columnas numéricas del dataframe\n",
        "columnas_numericas = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "for columna in columnas_numericas:\n",
        "    generar_boxplot(df, columna)"
      ],
      "id": "05b3ecf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Para el tratamiento de datos atípicos lo que vamos a realizar es la imputación de ellos mediante el método intercuartílico, pero también vamos a generar un dataset sin realizar ningún tratamiento de los datos outlayers presentes en el dataset para realizar pruebas posteriormente en la aplicación de modelos de machine learning para ver cuanta diferencia hay entre ambos casos."
      ],
      "id": "40434e47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_clean = df.copy()\n",
        "\n",
        "# Iteramos sobre cada columna numérica en el DataFrame.\n",
        "for col in df_clean.select_dtypes(include=['int64', 'float64']).columns:\n",
        "    # Calculamos el primer y tercer cuartil (Q1 y Q3)\n",
        "    Q1 = df_clean[col].quantile(0.25)\n",
        "    Q3 = df_clean[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1  # Rango intercuartílico\n",
        "    \n",
        "    # Definimos los límites inferior y superior\n",
        "    lower_limit = Q1 - 1.5 * IQR\n",
        "    upper_limit = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Imputamos los valores atípicos por los límites correspondientes\n",
        "    df_clean[col] = np.where(df_clean[col] < lower_limit, lower_limit, df_clean[col])\n",
        "    df_clean[col] = np.where(df_clean[col] > upper_limit, upper_limit, df_clean[col])\n",
        "\n",
        "# Verificamos algunos valores antes y después de la limpieza\n",
        "print(\"Datos antes de la limpieza:\")\n",
        "print(df.describe())\n",
        "print(\"\\nDatos después de la limpieza:\")\n",
        "print(df_clean.describe())"
      ],
      "id": "59d797c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparación de datos\n",
        "### Vamos a realizar el tratamiento de datos pasos a realizar\n",
        "### Convertir datos categóricos a numéricos para esto vamos a aplicar one hot encoder y label conder dependiendo a tipo de dato\n",
        "### Además de convertir los datos categóricos en general para aplicar estos datos en modelos de machine learning, además de verificar el balanceo de datos y aplicación de técnicas para corregir variables con outlayers\n"
      ],
      "id": "908c30d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Valores únicos en la columna '{column}':\")\n",
        "    print(unique_values)\n",
        "    print(\"\\n------------------------------------\\n\")"
      ],
      "id": "33b26076",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LabelEncoder\n",
        "### Parental_Involvement, Access_to_Resources, Motivation_Level,Family_Income,Teacher_Quality,Peer_Influence,"
      ],
      "id": "852b8477"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "le = LabelEncoder()\n",
        "df['Parental_Involvement'] = le.fit_transform(df['Parental_Involvement'].astype(str))\n",
        "\n",
        "df['Access_to_Resources'] = le.fit_transform(df['Access_to_Resources'].astype(str))\n",
        "\n",
        "df['Motivation_Level'] = le.fit_transform(df['Motivation_Level'].astype(str))\n",
        "\n",
        "df['Family_Income'] = le.fit_transform(df['Family_Income'].astype(str))\n",
        "\n",
        "df['Teacher_Quality'] = le.fit_transform(df['Teacher_Quality'].astype(str))\n",
        "\n",
        "df['Peer_Influence'] = le.fit_transform(df['Peer_Influence'].astype(str))\n",
        "\n",
        "df['Parental_Education_Level'] = le.fit_transform(df['Parental_Education_Level'].astype(str))\n",
        "\n",
        "df['Distance_from_Home'] = le.fit_transform(df['Distance_from_Home'].astype(str))\n",
        "\n",
        "# datos sin outlayers\n",
        "\n",
        "df_clean['Parental_Involvement'] = le.fit_transform(df_clean['Parental_Involvement'].astype(str))\n",
        "\n",
        "df_clean['Access_to_Resources'] = le.fit_transform(df_clean['Access_to_Resources'].astype(str))\n",
        "\n",
        "df_clean['Motivation_Level'] = le.fit_transform(df_clean['Motivation_Level'].astype(str))\n",
        "\n",
        "df_clean['Family_Income'] = le.fit_transform(df_clean['Family_Income'].astype(str))\n",
        "\n",
        "df_clean['Teacher_Quality'] = le.fit_transform(df_clean['Teacher_Quality'].astype(str))\n",
        "\n",
        "df_clean['Peer_Influence'] = le.fit_transform(df_clean['Peer_Influence'].astype(str))\n",
        "\n",
        "df_clean['Parental_Education_Level'] = le.fit_transform(df_clean['Parental_Education_Level'].astype(str))\n",
        "\n",
        "df_clean['Distance_from_Home'] = le.fit_transform(df_clean['Distance_from_Home'].astype(str))"
      ],
      "id": "6f294f0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OneHotEncoder\n",
        "\n",
        "### Internet_Access, Extracurricular_Activities, School_Type, Gender, ,Peer_Influence"
      ],
      "id": "8459c3c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Aplicar One-Hot Encoding\n",
        "df = pd.get_dummies(df, columns=['Extracurricular_Activities'])\n",
        "df = pd.get_dummies(df, columns=['Internet_Access'])\n",
        "df = pd.get_dummies(df, columns=['School_Type'])\n",
        "df = pd.get_dummies(df, columns=['Peer_Influence'])\n",
        "df = pd.get_dummies(df, columns=['Learning_Disabilities'])\n",
        "df = pd.get_dummies(df, columns=['Gender'])\n",
        "\n",
        "# datos sin outlayers\n",
        "\n",
        "df_clean = pd.get_dummies(df_clean, columns=['Extracurricular_Activities'])\n",
        "df_clean = pd.get_dummies(df_clean, columns=['Internet_Access'])\n",
        "df_clean = pd.get_dummies(df_clean, columns=['School_Type'])\n",
        "df_clean = pd.get_dummies(df_clean, columns=['Peer_Influence'])\n",
        "df_clean = pd.get_dummies(df_clean, columns=['Learning_Disabilities'])\n",
        "df_clean = pd.get_dummies(df_clean, columns=['Gender'])"
      ],
      "id": "09c278d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Valores únicos en la columna '{column}':\")\n",
        "    print(unique_values)\n",
        "    print(\"\\n------------------------------------\\n\")"
      ],
      "id": "bdb25a31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular la matriz de correlación\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Generar el mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Mapa de calor de la correlación entre variables')\n",
        "plt.show()"
      ],
      "id": "478ee910",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Filtrar solo las correlaciones con la variable objetivo\n",
        "target_corr = correlation_matrix['Exam_Score'].sort_values(ascending=False)\n",
        "print(\"Correlación de cada variable con 'Exam_Score':\\n\", target_corr)"
      ],
      "id": "fc5a7bdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aplicación de modelos de machine learning\n",
        "\n",
        "## Predicción con datos atípicos\n"
      ],
      "id": "a99aeacf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Separar las características (X) y la variable objetivo (y)\n",
        "X = df.drop(columns=['Exam_Score'])  # Todas las columnas excepto la variable objetivo\n",
        "y = df['Exam_Score']  # La variable objetivo\n",
        "\n",
        "# Dividir el conjunto de datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Lista de modelos de regresión para evaluar\n",
        "models = {\n",
        "    \"Regresión Lineal\": LinearRegression(),\n",
        "    \"Regresión Ridge\": Ridge(alpha=1.0),\n",
        "    \"Regresión Lasso\": Lasso(alpha=0.1),\n",
        "    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42,),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "results = []\n",
        "\n",
        "# Entrenar y evaluar cada modelo\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    # Almacenar los resultados\n",
        "    results.append({\n",
        "        \"Modelo\": model_name,\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R^2\": r2\n",
        "    })\n",
        "\n",
        "# Convertir los resultados en un DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Mostrar los resultados ordenados por R^2\n",
        "print(results_df.sort_values(by=\"R^2\", ascending=False))"
      ],
      "id": "213fd5da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Variables utilizadas\n",
        "print(\"Variables utilizadas en el modelo:\")\n",
        "print(X.columns)"
      ],
      "id": "eb340580",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Separar las variables independientes y la variable objetivo\n",
        "X = df.drop(columns=['Exam_Score'])\n",
        "y = df['Exam_Score']\n",
        "\n",
        "# Dividir el conjunto de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Definir los modelos base\n",
        "base_models = [\n",
        "    ('linear', LinearRegression()),\n",
        "    ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "# Definir el modelo meta\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Crear el Stacking Regressor\n",
        "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
        "\n",
        "# Entrenar el modelo\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Resultados del Stacking Regressor\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R^2: {r2:.4f}\")"
      ],
      "id": "fb88db90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicción sin datos atípicos"
      ],
      "id": "8b0bb14c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Separar las características (X) y la variable objetivo (y)\n",
        "X = df_clean.drop(columns=['Exam_Score'])  # Todas las columnas excepto la variable objetivo\n",
        "y = df_clean['Exam_Score']  # La variable objetivo\n",
        "\n",
        "# Dividir el conjunto de datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Lista de modelos de regresión para evaluar\n",
        "models = {\n",
        "    \"Regresión Lineal\": LinearRegression(),\n",
        "    \"Regresión Ridge\": Ridge(alpha=1.0),\n",
        "    \"Regresión Lasso\": Lasso(alpha=0.1),\n",
        "    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42,),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "results = []\n",
        "\n",
        "# Entrenar y evaluar cada modelo\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    # Almacenar los resultados\n",
        "    results.append({\n",
        "        \"Modelo\": model_name,\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R^2\": r2\n",
        "    })\n",
        "\n",
        "# Convertir los resultados en un DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Mostrar los resultados ordenados por R^2\n",
        "print(results_df.sort_values(by=\"R^2\", ascending=False))"
      ],
      "id": "3237aaee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Variables utilizadas\n",
        "print(\"Variables utilizadas en el modelo:\")\n",
        "print(X.columns)"
      ],
      "id": "4842ce83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Separar las variables independientes y la variable objetivo\n",
        "X = df_clean.drop(columns=['Exam_Score'])\n",
        "y = df_clean['Exam_Score']\n",
        "\n",
        "# Dividir el conjunto de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Definir los modelos base\n",
        "base_models = [\n",
        "    ('linear', LinearRegression()),\n",
        "    ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "# Definir el modelo meta\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Crear el Stacking Regressor\n",
        "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
        "\n",
        "# Entrenar el modelo\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Resultados del Stacking Regressor\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R^2: {r2:.4f}\")"
      ],
      "id": "c13e28f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparación de métricas de modelos\n",
        "\n",
        "\n",
        "### Comparación de resultados:\n",
        "\n",
        "1. **Sin Datos Atípicos:**\n",
        "\n",
        "- Los modelos mejoran su desempeño cuando los datos atípicos han sido ajustados.\n",
        "\n",
        "Stacking Regressor tiene el mejor rendimiento con:\n",
        "\n",
        "MAE: 0.8760 (error promedio bajo)\n",
        "\n",
        "RMSE: 1.2578 (mejor precisión comparado con los otros modelos)\n",
        "\n",
        "R²: 0.8588 (explica el 85.88% de la variabilidad en la variable objetivo)\n",
        "\n",
        "  \n",
        "\n",
        "- Random Forest y Regresión Ridge/Lineal presentan un desempeño similar en términos de MAE y RMSE, pero están ligeramente por debajo del Stacking Regressor.\n",
        "\n",
        "- Regresión Lasso tiene un poco más de error en comparación con Ridge/Lineal.\n",
        "\n",
        "- Árbol de Decisión muestra un rendimiento inferior con un MAE de 1.5109 y un R² de 0.6025, lo cual indica que no es tan eficaz en capturar la relación entre las variables.\n",
        "\n",
        "  \n",
        "\n",
        "2. **Con Datos Atípicos:**\n",
        "\n",
        "- Los modelos se ven significativamente afectados por la presencia de outliers.\n",
        "\n",
        "Stacking Regressor sigue siendo el mejor modelo en este caso, pero sus métricas son peores:\n",
        "\n",
        "MAE: 0.9709\n",
        "\n",
        "RMSE: 1.9767\n",
        "\n",
        "R²: 0.7131 (una caída considerable comparada con el caso sin outliers, indicando que el modelo explica menos la variabilidad de la variable objetivo).\n",
        "\n",
        "- Regresión Ridge/Lineal tienen un MAE de aproximadamente 1.008 y un RMSE de 2.016, indicando que los errores son mayores y su capacidad para predecir disminuye.\n",
        "\n",
        "- Random Forest y Lasso también ven una degradación en su rendimiento.\n",
        "\n",
        "- Árbol de Decisión se ve severamente afectado, con un R² cercano a 0, lo que sugiere que apenas explica la variabilidad de la variable objetivo.\n",
        "\n",
        "  \n",
        "\n",
        "### Conclusiones:\n",
        "\n",
        "- Impacto de los Outliers: Los datos atípicos tienden a distorsionar las predicciones de los modelos, especialmente aquellos que no son robustos a valores extremos, como los árboles de decisión. Esto resulta en una mayor imprecisión (valores de MAE y RMSE más altos) y una menor capacidad de explicación (valores de R² más bajos).\n",
        "\n",
        "- Importancia del Preprocesamiento: Ajustar los outliers ha mejorado el rendimiento de todos los modelos, especialmente del Stacking Regressor. Esto sugiere que los datos limpios permiten a los modelos captar mejor las relaciones entre las variables."
      ],
      "id": "2c6ec0f9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\lea\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}